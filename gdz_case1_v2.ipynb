{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "trainDF = pd.read_csv(\"train.csv\")\n",
    "trafoDF = pd.read_csv(\"trafo.csv\")\n",
    "submissionDF = pd.read_csv(\"submission.csv\")\n",
    "bagilNemDF = pd.read_csv(\"Hava Durumu/Bağıl Nem.csv\")\n",
    "bulutsuzlukOraniDF = pd.read_csv(\"Hava Durumu/Bulutluluk Oranı.csv\")\n",
    "radyasyonDF = pd.read_csv(\"Hava Durumu/Radyasyon.csv\")\n",
    "ruzgarHiziDF = pd.read_csv(\"Hava Durumu/Rüzgar Hızı.csv\")\n",
    "ruzgarYonuDF = pd.read_csv(\"Hava Durumu/Rüzgar Yönü.csv\")\n",
    "sicaklikDF = pd.read_csv(\"Hava Durumu/Sıcaklık.csv\")\n",
    "yagisDF = pd.read_csv(\"Hava Durumu/Yağış.csv\")\n",
    "\n",
    "radyasyonDF.drop(\"Unnamed: 17\",axis=1,inplace=True) # bilinmeyen kolon ve içeriği boş olduğu için drop ediyoruz\n",
    "trainDF.drop(\"BİLDİRİME_GÖRE\",axis=1,inplace=True) # Bu kolon için tüm degerler aynı,bir katkısı olmayacak bu sebeple drop ediyoruz\n",
    "trainDF.drop([\"KOD_NO\",\"KADEME\"],axis=1,inplace=True) # Bu kolonların için tüm degerleri null,bir katkısı olmayacak bu sebeple drop ediyoruz\n",
    "\n",
    "\n",
    "def tr_capitalize(param_word):\n",
    "    word_list = param_word.split(sep=\" \")\n",
    "    new_word = \"\"\n",
    "    for word in word_list:\n",
    "        first_letter = word[0]\n",
    "        last_part = word[1:]\n",
    "\n",
    "        first_letter = re.sub(r\"i\", \"İ\", first_letter)\n",
    "        first_letter = re.sub(r\"ı\", \"I\", first_letter)\n",
    "        first_letter = re.sub(r\"ç\", \"Ç\", first_letter)\n",
    "        first_letter = re.sub(r\"ş\", \"Ş\", first_letter)\n",
    "        first_letter = re.sub(r\"ü\", \"Ü\", first_letter)\n",
    "        first_letter = re.sub(r\"ğ\", \"Ğ\", first_letter)\n",
    "\n",
    "        last_part = re.sub(r\"İ\", \"i\", last_part)\n",
    "        last_part = re.sub(r\"I\", \"ı\", last_part)\n",
    "        last_part = re.sub(r\"Ç\", \"ç\", last_part)\n",
    "        last_part = re.sub(r\"Ş\", \"ş\", last_part)\n",
    "        last_part = re.sub(r\"Ü\", \"ü\", last_part)\n",
    "        last_part = re.sub(r\"Ğ\", \"ğ\", last_part)\n",
    "\n",
    "        rebuilt_word = first_letter + last_part\n",
    "        rebuilt_word = rebuilt_word.capitalize()\n",
    "        new_word = new_word + \" \" + rebuilt_word\n",
    "\n",
    "    new_word = new_word.strip()\n",
    "    return new_word\n",
    "\n",
    "    \n",
    "trainDF[\"BAŞLAMA_TARİHİ\"] = pd.to_datetime(trainDF[\"BAŞLAMA_TARİHİ_VE_ZAMANI\"], dayfirst=True).dt.date\n",
    "trainDF[\"SONA_ERME_TARİHİ\"] = pd.to_datetime(trainDF[\"SONA_ERME_TARİHİ_VE_ZAMANI\"], dayfirst=True).dt.date\n",
    "\n",
    "bagilNemDF[\"Tarih\"]=pd.to_datetime(bagilNemDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "radyasyonDF[\"Tarih\"]=pd.to_datetime(radyasyonDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "bulutsuzlukOraniDF[\"Tarih\"]=pd.to_datetime(bulutsuzlukOraniDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "ruzgarHiziDF[\"Tarih\"]=pd.to_datetime(ruzgarHiziDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "ruzgarYonuDF[\"Tarih\"]=pd.to_datetime(ruzgarYonuDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "sicaklikDF[\"Tarih\"]=pd.to_datetime(sicaklikDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "yagisDF[\"Tarih\"]=pd.to_datetime(yagisDF[\"Tarih\"], dayfirst=True,errors='coerce').dt.date\n",
    "\n",
    "\n",
    "minDate = trainDF[\"BAŞLAMA_TARİHİ\"].min()\n",
    "\n",
    "# hava durumu ile ilgili dataframelerin tarihini traindf nin en düşük tarihine göre filtreliyoruz\n",
    "bagilNemDF=bagilNemDF[bagilNemDF[\"Tarih\"] >= minDate]\n",
    "bulutsuzlukOraniDF=bulutsuzlukOraniDF[bulutsuzlukOraniDF[\"Tarih\"] >= minDate]\n",
    "radyasyonDF=radyasyonDF[radyasyonDF[\"Tarih\"] >= minDate]\n",
    "ruzgarHiziDF=ruzgarHiziDF[ruzgarHiziDF[\"Tarih\"] >= minDate]\n",
    "ruzgarYonuDF=ruzgarYonuDF[ruzgarYonuDF[\"Tarih\"] >= minDate]\n",
    "sicaklikDF=sicaklikDF[sicaklikDF[\"Tarih\"] >= minDate]\n",
    "yagisDF=yagisDF[yagisDF[\"Tarih\"] >= minDate]\n",
    "\n",
    "\n",
    "trafo_date=submissionDF[\"trafo_id_date\"].str.split(\"__\",expand=True)\n",
    "submissionDF[\"trafo_id\"]  = trafo_date[0]\n",
    "submissionDF[\"Tarih\"]  = trafo_date[1]\n",
    "submissionDF.drop(\"trafo_id_date\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "havaDurumuLokasyonlar = list(set(itertools.chain(bagilNemDF.columns,bulutsuzlukOraniDF.columns,radyasyonDF.columns,ruzgarHiziDF.columns,ruzgarYonuDF.columns,sicaklikDF.columns,yagisDF.columns)))\n",
    "\n",
    "trainDF[\"İL\"]=trainDF[\"İL\"].apply(lambda x: tr_capitalize(x))\n",
    "trainDF[\"İLÇE\"]=trainDF[\"İLÇE\"].apply(lambda x: tr_capitalize(x))\n",
    "trainDF[\"LOKASYON\"] = trainDF[[\"İL\",\"İLÇE\"]].apply(lambda x: x[\"İLÇE\"] if x[\"İLÇE\"] in havaDurumuLokasyonlar else x[\"İL\"], axis=1)\n",
    "trainDF.drop([\"İL\",\"İLÇE\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her saatır için lokasyon(il ve ilçeye göre) ve tarihe göre hava durumu ortalama degerlerini yeni bir kolonda gösteriyoruz\n",
    "# for dfDegisken in [bagilNemDF,bulutsuzlukOraniDF,radyasyonDF,ruzgarHiziDF,ruzgarYonuDF,sicaklikDF,yagisDF]:\n",
    "#     ortalama = dfDegisken.groupby(\"Tarih\").mean().to_dict()\n",
    "#     tarihler=dfDegisken.groupby(\"Tarih\").mean().index\n",
    "#     if(str(dfDegisken)==str(bagilNemDF)):\n",
    "#         kolon_adi=\"BAĞIL_NEM\"\n",
    "#     elif(str(dfDegisken)==str(bulutsuzlukOraniDF)):\n",
    "#         kolon_adi=\"BULUTSUZLUK_ORANI\"\n",
    "#     elif(str(dfDegisken)==str(radyasyonDF)):\n",
    "#         kolon_adi=\"RADYASYON\"\n",
    "#     elif(str(dfDegisken)==str(ruzgarHiziDF)):\n",
    "#         kolon_adi=\"RUZGAR_HIZI\"\n",
    "#     elif(str(dfDegisken)==str(ruzgarYonuDF)):\n",
    "#         kolon_adi=\"RUZGAR_YONU\"\n",
    "#     elif(str(dfDegisken)==str(sicaklikDF)):\n",
    "#         kolon_adi=\"SICAKLIK\"\n",
    "#     elif(str(dfDegisken)==str(yagisDF)):\n",
    "#         kolon_adi=\"YAGIS\"\n",
    "    \n",
    "#     trainDF[kolon_adi] = trainDF.apply(lambda x: ortalama[x[\"LOKASYON\"]][x[\"BAŞLAMA_TARİHİ\"]] if x[\"BAŞLAMA_TARİHİ\"] in tarihler else 0.0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tarih</th>\n",
       "      <th>trafo_id</th>\n",
       "      <th>LOKASYON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Urla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>2</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Bergama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007139</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>63762</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007140</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>63763</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007141</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>63764</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007142</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>63765</td>\n",
       "      <td>Akhisar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007143</th>\n",
       "      <td>2022-06-12</td>\n",
       "      <td>63766</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26007144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tarih  trafo_id LOKASYON\n",
       "0        2021-05-01         0     Urla\n",
       "1        2021-05-01         1    İzmir\n",
       "2        2021-05-01         2    İzmir\n",
       "3        2021-05-01         3  Bergama\n",
       "4        2021-05-01         4    İzmir\n",
       "...             ...       ...      ...\n",
       "26007139 2022-06-12     63762    İzmir\n",
       "26007140 2022-06-12     63763    İzmir\n",
       "26007141 2022-06-12     63764    İzmir\n",
       "26007142 2022-06-12     63765  Akhisar\n",
       "26007143 2022-06-12     63766    İzmir\n",
       "\n",
       "[26007144 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF=pd.merge(trainDF,trafoDF,on='ŞEBEKE_UNSURU_KODU',how='left')\n",
    "trainDF['target']=1\n",
    "#start -> trainDF[\"BAŞLAMA_TARİHİ\"]).min() and end -> trainDF[\"BAŞLAMA_TARİHİ\"]).max()\n",
    "dframe=pd.DataFrame(pd.date_range(start='5/1/2021', end='6/12/2022', freq='D'))\n",
    "dframe.rename(columns={0:\"Tarih\"},inplace=True)\n",
    "\n",
    "uniqueTrafo=pd.DataFrame()\n",
    "uniqueTrafo[\"trafo_id\"]=trainDF[\"trafo_id\"].unique()\n",
    "# uniqueTrafo=uniqueTrafo.merge(trainDF[[\"trafo_id\",\"LOKASYON\"]],on=\"trafo_id\",how=\"inner\").drop_duplicates()\n",
    "# dframe=dframe.merge(uniqueTrafo[[\"trafo_id\",\"LOKASYON\"]], how='cross')\n",
    "\n",
    "uniqueTrafo=uniqueTrafo.merge(trainDF[\"trafo_id\"],on=\"trafo_id\",how=\"inner\").drop_duplicates()\n",
    "dframe=dframe.merge(uniqueTrafo[\"trafo_id\"], how='cross')\n",
    "\n",
    "trainDF.rename(columns={\"BAŞLAMA_TARİHİ\":\"Tarih\"},inplace=True)\n",
    "trainDF[\"Tarih\"]=trainDF[\"Tarih\"].astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "trafo_lokasyon=trainDF[[\"trafo_id\",\"LOKASYON\"]].drop_duplicates()\n",
    "finalDF = pd.merge(dframe,trafo_lokasyon, on=['trafo_id'],how=\"left\")\n",
    "\n",
    "finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LOKASYON'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eminkbc\\Desktop\\gdz22_1\\gdz_case1_v2.ipynb Hücre 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nem[nem[\u001b[39m\"\u001b[39m\u001b[39mLOKASYON\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mİzmir\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nem[\u001b[39m\"\u001b[39m\u001b[39mTarih\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_datetime(nem[\u001b[39m\"\u001b[39m\u001b[39mTarih\u001b[39m\u001b[39m\"\u001b[39m], dayfirst\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m finalDF \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(finalDF,nem, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mTarih\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mLOKASYON\u001b[39;49m\u001b[39m\"\u001b[39;49m],how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m finalDF \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(finalDF,trainDF, on\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mTarih\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtrafo_id\u001b[39m\u001b[39m'\u001b[39m],how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m finalDF[finalDF[\u001b[39m\"\u001b[39m\u001b[39mKESİNTİ_NO\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misna()]\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    108\u001b[0m         left,\n\u001b[0;32m    109\u001b[0m         right,\n\u001b[0;32m    110\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    111\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    112\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    113\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    114\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    115\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    116\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    117\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    118\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    119\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    120\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[0;32m    695\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m--> 700\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(rk)\n\u001b[0;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m lk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1110\u001b[0m     left_keys\u001b[39m.\u001b[39mappend(left\u001b[39m.\u001b[39;49m_get_label_or_level_values(lk))\n\u001b[0;32m   1111\u001b[0m     join_names\u001b[39m.\u001b[39mappend(lk)\n\u001b[0;32m   1112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1113\u001b[0m     \u001b[39m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:1848\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mget_level_values(key)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1850\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LOKASYON'"
     ]
    }
   ],
   "source": [
    "nem = bagilNemDF.melt(id_vars = 'Tarih', var_name = 'LOKASYON', value_name = 'BAĞIL_NEM').groupby([\"Tarih\",\"LOKASYON\"]).mean().reset_index()\n",
    "nem[nem[\"LOKASYON\"]==\"İzmir\"]\n",
    "nem[\"Tarih\"]=pd.to_datetime(nem[\"Tarih\"], dayfirst=True)\n",
    "\n",
    "finalDF = pd.merge(finalDF,nem, on=['Tarih',\"LOKASYON\"],how=\"left\")\n",
    "finalDF = pd.merge(finalDF,trainDF, on=[\"Tarih\",'trafo_id'],how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF[finalDF[\"KESİNTİ_NO\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LOKASYON'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eminkbc\\Desktop\\gdz22_1\\gdz_case1_v2.ipynb Hücre 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m merged \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(finalDF,trainDF, on\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mTarih\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtrafo_id\u001b[39m\u001b[39m'\u001b[39m],how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eminkbc/Desktop/gdz22_1/gdz_case1_v2.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m merged[\u001b[39m\"\u001b[39;49m\u001b[39mBAĞIL_NEM\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mLOKASYON\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1922\u001b[0m, in \u001b[0;36mSeries.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   1918\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   1920\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"SeriesGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 1922\u001b[0m \u001b[39mreturn\u001b[39;00m SeriesGroupBy(\n\u001b[0;32m   1923\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1924\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   1925\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   1926\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   1927\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   1928\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   1929\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   1930\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1931\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   1932\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   1933\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\eminkbc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LOKASYON'"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(finalDF,trainDF, on=[\"Tarih\",'trafo_id'],how=\"left\")\n",
    "merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1235a4a0d137df5292140eb52adc627bffa45ff4395dc88783d325bfa7b4fac3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
